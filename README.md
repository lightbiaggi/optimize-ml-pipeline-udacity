# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
The dataset contains demographic , work and salary data that will be used to predict if the person does or not qualify for loan.
we will use automl vs hyperdrive to see which one has performed the best

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
For scikit learn i used random sampling , though it will have performance compared to grid but that what i selected 
I used medianstopping policy with evaluation_interval = 1 and delay_evaluation = 0
In hyperpatameter configuration  I have  accuracy as primary metric and the goal is maximize it with max total runs of 100 with ability of have max of 4 runs concurrently
**What are the benefits of the parameter sampler you chose?**
Random sampling supports discrete and continuous hyperparameters, early termination of low-performance runs.
grid does not support continuous parameters

**What are the benefits of the early stopping policy you chose?**
medianstopping policy is used for conservative policy that provides savings without terminating promising jobs, it can provide approximately 25%-35% savings with no loss on primary metric

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
deploy the model to the model registery using both ways . using inference and having end points for consuming the service

## Proof of cluster clean up

